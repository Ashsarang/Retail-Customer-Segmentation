{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "yLjJCtPM0KBk",
        "67NQN5KX2AMe",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Project Name**    - **Online Retail Customer Segmentation**\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Unsupervised\n",
        "##### **Contribution**    - Individual\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Customer segmentation is a crucial strategy in business and marketing, involving the division of a broad customer base into distinct groups based on shared characteristics or behaviors. This approach enables businesses to gain a deeper understanding of their customers, address their needs more effectively, and optimize various aspects of their operations. As a result, companies can achieve enhanced marketing efficiency, higher customer satisfaction, and improved overall business performance."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, your task is to identify major customer segments within a transnational data set encompassing all transactions from 01/12/2010 to 09/12/2011 for a UK-based, non-store online retailer. The company primarily sells unique, all-occasion gifts, with many of its customers being wholesalers."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd       # Library for data analysis\n",
        "import numpy as np          # Basic mathematic operation\n",
        "\n",
        "import matplotlib.pyplot as plt     # Library for visualization\n",
        "import matplotlib.cm as cm            # Tool for enhancing data visualizations through effective use of color\n",
        "import seaborn as sns             # High level interface for drawing a informative staticals graph.\n",
        "%matplotlib inline\n",
        "import missingno as msno          # Library for visualize the missing Data.\n",
        "\n",
        "from datetime import datetime     # For Handling Datatime data\n",
        "import datetime as dt\n",
        "from numpy import math\n",
        "\n",
        "import scipy.stats as stats\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler   # Standardize features in dataset.\n",
        "from sklearn.cluster import KMeans            # Importing kMeans ML model\n",
        "from sklearn.cluster import DBSCAN            # Importing Dbscan ML model\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Alma Better EDA files/Online Retail.xlsx - Online Retail.csv\")"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First five rows\n",
        "df.head()\n",
        ""
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# last Five rows\n",
        "df.tail()"
      ],
      "metadata": {
        "id": "wfzAm31IRW9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "print(f\" Number of Rows: {df.shape[0]} \")\n",
        "print(f\"Number of columns: {df.shape[1]}\")"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "df[df.duplicated()]"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "msno.bar(df, figsize=(6,4),color=\"seagreen\",fontsize=12)"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   This dataset comprises 541,909 rows and 8 columns.\n",
        "*   There are 5,268 duplicate rows.\n",
        "*   The columns \"Description\" and \"customer_id\" contain null values\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "InvoiceNo: Invoice number. A 6-digit integral number uniquely assigned to each transaction. If this code starts with letter 'c', it indicates a cancellation.\n",
        "\n",
        "StockCode: Product (item) code— a 5-digit integral number uniquely assigned to each distinct product.\n",
        "\n",
        "Description: Product (item) name.\n",
        "\n",
        "Quantity: The quantities of each product (item) per transaction.\n",
        "\n",
        "InvoiceDate: Invoice date and time.\n",
        "\n",
        "Unit Price: Product price per unit.\n",
        "\n",
        "CustomerID: Customer number, a 5-digit integral number uniquely assigned to each customer.\n",
        "\n",
        "Country: Country name. The name of the country where each customer resides."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for i in df.columns:\n",
        "  unique = df[i].unique()\n",
        "  print(f\"Unique value for {i}: {unique}\")\n",
        "  print(\"--\"*50)"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "# Droping the null values\n",
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking null values\n",
        "df.isnull().any()\n",
        ""
      ],
      "metadata": {
        "id": "EmWmVRAXTbht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# changing datatype\n",
        "df['InvoiceNo'] = df['InvoiceNo'].astype('str')"
      ],
      "metadata": {
        "id": "zVwIVkSnTbeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Here we dropped some InvoiceNo which starts with 'c' because 'c' indicates a cancellation."
      ],
      "metadata": {
        "id": "pjyWtfh9Tk23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# droping the rows which contain c\n",
        "df = df[~df['InvoiceNo'].str.contains('C')]"
      ],
      "metadata": {
        "id": "sQ-EUkkDTbbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# droping the duplicate values\n",
        "df.drop_duplicates(inplace = True)"
      ],
      "metadata": {
        "id": "Y35CeyMSTbYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating new features TotalAmount\n",
        "df['TotalAmount'] = df['Quantity'] * df['UnitPrice']"
      ],
      "metadata": {
        "id": "kfNWXFrUTbKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting InvoiceDate column into datetime format\n",
        "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'], format='%d/%m/%y %H:%M', errors='coerce')\n",
        "\n"
      ],
      "metadata": {
        "id": "B-8SoeqrTwSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# creating new column from InvoiceDate\n",
        "df['Month'] = df['InvoiceDate'].dt.month_name()\n",
        "df['Day']   = df['InvoiceDate'].dt.day_name()\n",
        "df['Hour']  = df['InvoiceDate'].dt.hour"
      ],
      "metadata": {
        "id": "x0MYXb5uTwPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "9UL7eJ4kTwMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   I have removed the null values present in the \"Description\" and \"Customer\" columns.\n",
        "*   In the \"InvoiceNo\" column, \"C\" indicates a cancellation; therefore, I have removed the rows where \"InvoiceNo\" contains \"C\".\n",
        "*   I have also removed the duplicate values present in our dataset.\n",
        "*   I created a new feature, \"TotalAmount,\" by multiplying \"Quantity\" and \"UnitPrice.\"\n",
        "*   I have also created three new columns: \"Month,\" \"Day,\" and \"Hour\" from the \"InvoiceDate\" column.\n",
        "\n"
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chart - 1 **Top 10 Highest spending customer**."
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "top_cust = df.groupby(['CustomerID'])['TotalAmount'].sum().reset_index()\n",
        "top_10_cust = top_cust.sort_values('TotalAmount', ascending=False).head(10)\n",
        "print(top_10_cust)\n",
        "\n",
        "plt.figure(figsize=(10,8)) # Graph size\n",
        "sns.set_style('darkgrid') # Style of Grpah\n",
        "# Bar plot\n",
        "sns.barplot(x = 'CustomerID', y = 'TotalAmount', data = top_10_cust)\n",
        "#Title of Graph\n",
        "plt.title(\"Highest Spending Customer\",color='navy')\n",
        "# Labels of Graph\n",
        "plt.xlabel(\"Customer ID\",color = 'blue')\n",
        "plt.ylabel(\"Total Amount Spend\",color='blue')\n",
        "# Showing Graph\n",
        "plt.show()\n",
        ""
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bar charts are great for comparing different categories."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   The top spenders are revealed in this graph, with the ten highest-value customers identified.\n",
        "*   customer ID 14646 and 18102 spend most.\n",
        "\n"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2 **Top 10 Product by Unit Counts**"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "description = df['Description'].value_counts().reset_index()\n",
        "description_df = description.head(10)\n",
        "print(description_df)\n",
        "\n",
        "plt.figure(figsize=(12,8))   # Graph size\n",
        "\n",
        "sns.set_style(\"whitegrid\")  # Style of Graph\n",
        "\n",
        "sns.barplot(data = description_df, x = 'count', y = 'Description',palette = 'viridis')\n",
        "# Title of Graph\n",
        "plt.title(\"Top Product by Unit Count\", color='navy')\n",
        "# Label of Graph\n",
        "plt.xlabel(\"Number of Product\",color='blue')\n",
        "plt.ylabel(\"Product Name\", color='blue')\n",
        "# Showing Grpah\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The best tool for displaying comparisons between several categories of data. Horizontal rectangles leave enough room for textual information and are therefore ideal for long data labels."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This graph reveals our best-selling product."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3 **Top 10 Best Selling products.**"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_product = df.groupby(['Description'])['TotalAmount'].sum().sort_values(ascending=False).reset_index().head(10)\n",
        "print(top_product)\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.set_style('darkgrid')\n",
        "\n",
        "sns.barplot(x = 'TotalAmount', y= 'Description',data = top_product, palette=\"rocket\")\n",
        "# Graph title\n",
        "plt.title(\" Best Selling Products\", color='navy')\n",
        "# Graph lebel\n",
        "plt.xlabel(\"Total Amount\", color='blue')\n",
        "plt.ylabel(\"Product Description\", color='blue')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   This visualization shows which product generated the highest sales revenue.\n",
        "*   Interestingly, while the graph shows \"WHITE HANGING HEART T-LIGHT HOLDER\" as the top seller in terms of units sold, \" PAPER CRAFT , LITTLE BIRDIE \" generated the highest total sales revenue.\n",
        "\n"
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4 **Top 10 Customers with Most Frequent Purchases**"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "customer_purchases_frequent = df['CustomerID'].value_counts().sort_values(ascending= False).reset_index()\n",
        "top_frequent_purchaser_df = customer_purchases_frequent.head(10)\n",
        "print(top_frequent_purchaser_df)\n",
        "\n",
        "plt.figure(figsize=(10,6))  # Graph size\n",
        "sns.set_style(\"darkgrid\")   # Graph style\n",
        "\n",
        "sns.barplot(x= 'CustomerID', y= 'count', palette= \"Paired\", data= top_frequent_purchaser_df)\n",
        "\n",
        "# Setting graph title and labels\n",
        "plt.title(\"Customers with Most Frequent Purchases\",color='navy')\n",
        "plt.xlabel(\"CustomerId\", color='blue')\n",
        "plt.ylabel(\"Purchases Frequency\",color='blue')\n",
        "# Showing the graph\n",
        "plt.show()\n",
        ""
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   The top customers in terms of purchase frequency are revealed in this graph.\n",
        "*   We can likewise says that they are most faithful clients.\n",
        "\n"
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5 **Top 5 Countries with the Most Potential Customers**"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "country_customer_count = df['Country'].value_counts().sort_values(ascending=False).reset_index()\n",
        "country_customer_count_df = country_customer_count.head(5)\n",
        "print(country_customer_count_df)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "\n",
        "sns.barplot(x = 'count', y='Country',data = country_customer_count_df, palette='magma')\n",
        "# setting title and labels of Graph.\n",
        "plt.title(\"Country with the Most Potential Customers\",color='navy')\n",
        "plt.xlabel(\"Count of Customers\",color='blue')\n",
        "plt.ylabel(\"Country Name\",color='blue')\n",
        "# showing graph\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   The largest number of customers are from the UK, followed by Germany and France.\n",
        "\n"
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6 **Country with the Highest Customer Expenditure.**"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "country_expenditure_df = df.groupby(['Country'])['TotalAmount'].sum().sort_values(ascending=False).reset_index().head()\n",
        "print(country_expenditure_df)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.set_style('darkgrid')\n",
        "sns.barplot(x = 'Country', y='TotalAmount',data = country_expenditure_df, palette='bright')\n",
        "# setting title and labels of Graph.\n",
        "plt.title(\"Top 5 Counrty witht he Highest Customer Expenditure\",color='navy')\n",
        "plt.xlabel(\"Country Name\",color='blue')\n",
        "plt.ylabel(\"Total Expenditure\",color='blue')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The top spending customers are primarily from the UK, followed by those from the Netherlands and EIRE."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7 **Monthly Trend in Total Spending**"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "monthly_spending = df.groupby(['Month'])['TotalAmount'].sum().reset_index()\n",
        "print(monthly_spending)\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "# Line Plot\n",
        "plt.plot(monthly_spending['Month'],  monthly_spending['TotalAmount'], marker='o',mec='red',mfc='green',ms=8)\n",
        "# Graph Title\n",
        "plt.title(\"Monthy Trend in Total Spending\",color='navy')\n",
        "# Graph Labels\n",
        "plt.xlabel(\"Month Name\",color='blue')\n",
        "plt.ylabel(\"Total Amount Spend\",color='blue')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Line graphs are excellent for showing trends over time. By plotting Total amount spend against months, you can easily observe how the values change from one month to the next."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   Most numbers of customers have purchased the gifts in the month of November, October and December.As we all know they have festive season in end of the year as well new year to celebrate so we have highest numbers of transaction in november, october, december as company have most of the customer wholesales who are keeping stocks for festive season.\n",
        "*   Least numbers of purchasing are in the month of April and February.\n",
        "\n"
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8 **Daily Transaction Volume.**"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "day_df = df['Day'].value_counts().reset_index()\n",
        "day_df\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "# Line Plot\n",
        "plt.plot(day_df['Day'], day_df['count'], marker='*',mec='red',ms=10)\n",
        "# Graph Title\n",
        "plt.title(\"Daily Transaction Volume \",color='navy')\n",
        "# Graph Labels\n",
        "plt.xlabel(\"Day Name\",color='blue')\n",
        "plt.ylabel(\"Number of transaction\",color='blue')\n",
        "plt.show()\n",
        ""
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   We can see the maximum number of transaction are for thursday but we can also see there are no transaction on saturday\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9 **Hourly Transaction Volume**"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hour_df = df.groupby(['Hour'])['TotalAmount'].sum().reset_index()\n",
        "print(hour_df)\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.barplot(x = 'Hour', y = 'TotalAmount', data = hour_df, palette = 'viridis')\n",
        "# Title of Graph\n",
        "plt.title(\"Hourly Transaction Volume\",color='navy')\n",
        "# Labels of Grpah\n",
        "plt.xlabel(\"Hour\",color='blue')\n",
        "plt.ylabel(\"Transaction Volume\",color='blue')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   From the above graph we can say that most numbers of purchasing is done between 12pm clock to 3pm.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "numeric_df = df[df.describe().columns] # Numeric columns\n",
        "correlation_matrix = numeric_df.corr()  # Correlation matrix of numeric data\n",
        "\n",
        "sns.heatmap(correlation_matrix, cmap='coolwarm', annot = True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correlation coefficients quantify the strength and direction of the linear relationship between two variables. By incorporating correlation values into a heatmap, you can quickly see which variables are positively correlated, negatively correlated or not correlated at all.\n",
        "\n",
        "Heatmaps visually represent data using color gradients, making it easier to spot patterns and trends."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H0): There is no significant difference in the average sales between Thursdays and Wednesdays compared to the average sales on all other days of the week combined.\n",
        "\n",
        "Alternative Hypothesis (H1): There is a significant difference in the average sales between Thursdays and Wednesdays compared to the average sales on all other days of the week combined."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "day_df1 = df[df['Day'].isin(['Wednesday', 'Thursday'])][['TotalAmount']]\n",
        "day_df2 = df[~df['Day'].isin(['Wednesday', 'Thursday'])][['TotalAmount']]\n",
        "\n",
        "# applying ttest\n",
        "t_statistic, p_value = stats.ttest_ind(day_df1, day_df2, equal_var=False)\n",
        "\n",
        "print(f\"t_statistic: {t_statistic}\")\n",
        "print(f\"p_value: {p_value}\")\n",
        "\n",
        "# significance level(alpha)\n",
        "alpha = 0.05\n",
        "\n",
        "#Analyze the results\n",
        "if p_value < alpha:\n",
        "  print(\"Reject Null Hypothesis\")\n",
        "else:\n",
        "  print(\"Fail to Reject Null Hypothesis\")"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have perform t-test to obtain P-Value."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A t-test is a statistical method well-suited to determining if a significant difference exists between the average sales on Thursdays and Wednesdays compared to the average sales on all other weekdays combined."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H0): There is no significant difference in the average sales between December, November and October compared to the average sales on all other months.\n",
        "\n",
        "Alternative Hypothesis (H1): There is a significant difference in the average sales between December, November and October compared to the average sales on all other months.Answer Here."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Perform Statistical Test to obtain P-Value\n",
        "day_df1 = df[df['Month'].isin(['December', 'November','October'])][['TotalAmount']]\n",
        "day_df2 = df[~df['Month'].isin(['December', 'November','October'])][['TotalAmount']]\n",
        "\n",
        "# applying ttest\n",
        "t_statistic, p_value = stats.ttest_ind(day_df1, day_df2, equal_var=False)\n",
        "\n",
        "print(f\"t_statistic: {t_statistic}\")\n",
        "print(f\"p_value: {p_value}\")\n",
        "\n",
        "# significance level(alpha)\n",
        "alpha = 0.05\n",
        "\n",
        "#Analyze the results\n",
        "if p_value < alpha:\n",
        "  print(\"Reject Null Hypothesis\")\n",
        "else:\n",
        "  print(\"Fail to Reject Null Hypothesis\")"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have perform t-test to obtain P-Value."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A t-test is a statistical method well-suited to determining if a significant difference exists between the average sales on December, November and October compared to the average sales on all other months combined."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H0): There is no significant difference in the average quantity purchased per invoice between different customers.\n",
        "\n",
        "Alternative Hypothesis (H1): There is a significant difference in the average quantity purchased per invoice between different customers."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Group by customerId and invoiceid to get average quantity per invoice for each customer\n",
        "df_grouped = df.groupby(['CustomerID', 'InvoiceNo']).agg({'Quantity': 'mean'}).reset_index()\n",
        "\n",
        "# Extract necessary columns\n",
        "customer_quantities = df_grouped[['CustomerID', 'Quantity']]\n",
        "\n",
        "# Create a list of arrays for each customer's quantities\n",
        "quantities_per_customer = [group['Quantity'].values for name, group in customer_quantities.groupby('CustomerID')]\n",
        "\n",
        "# Perform one-way ANOVA\n",
        "f_stat, p_value = stats.f_oneway(*quantities_per_customer)\n",
        "\n",
        "print(f\"F-statistic: {f_stat}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: There is a significant difference in the average quantity purchased per invoice between different customers.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: There is no significant difference in the average quantity purchased per invoice between different customers.\")\n",
        ""
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have performs a one-way ANOVA to test the null hypothesis that there is significant difference in the average quantity purchased per invoice between different customers."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have dropped the null value."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Taging"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely."
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1 Create the RFM model (Recency, Frequency,Monetary value)"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "\n",
        "#Set Latest date 2011-12-10 as last invoice date was 2011-12-09. This is to calculate the number of days from recent purchase\n",
        "Latest_Date = dt.datetime(2011,12,10)\n",
        "#Create RFM Modelling scores for each customer\n",
        "rfm_df = df.groupby('CustomerID').agg({'InvoiceDate': lambda x: (Latest_Date - x.max()).days,\n",
        "                                       'InvoiceNo': lambda x: len(x),\n",
        "                                       'TotalAmount': lambda x: x.sum()})\n",
        "\n",
        "# Handle non-finite values before converting to integer\n",
        "rfm_df['InvoiceDate'] = rfm_df['InvoiceDate'].fillna(0).astype(int) # Replace NaN with 0, then convert to int\n",
        "\n",
        "#Rename column names to Recency, Frequency and Monetary\n",
        "rfm_df.rename(columns={'InvoiceDate': 'Recency',\n",
        "                         'InvoiceNo': 'Frequency',\n",
        "                         'TotalAmount': 'Monetary'}, inplace=True)\n",
        "\n",
        "rfm_df.reset_index().head()"
      ],
      "metadata": {
        "id": "E07mDNiKL1yi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RFM is a method used for analyzing customer value. It is commonly used in database marketing and direct marketing and has received particular attention in retail and professional services industries.\n",
        "\n",
        "Recency – How recently did the customer purchase?\n",
        "\n",
        "Frequency – How often do they purchase?\n",
        "\n",
        "Monetary – How much do they spend?\n",
        "\n",
        "Recency - In order to find the recency value of each customer, we need to determine the last invoice date as the current date and subtract the last purchasing date of each customer from this date.\n",
        "\n",
        "Frequency - In order to find the frequency value of each customer, we need to determine how many times the customers make purchases.\n",
        "\n",
        "Monetary - In order to find the monetary value of each customer, we need to determine how much do the customers spend on purchases."
      ],
      "metadata": {
        "id": "LjNDmYh4MlTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Descriptive Statistics\n",
        "rfm_df.describe().T"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution plot\n",
        "# plots size\n",
        "fig, axes = plt.subplots(1,3,figsize=(20,5))\n",
        "sns.histplot(rfm_df['Recency'], ax = axes[0],color='gray', kde=True)  # Recency Distribution\n",
        "axes[0].set_title('Recency Distribution')\n",
        "\n",
        "sns.histplot(rfm_df['Frequency'], ax = axes[1],color='brown', kde=True)  # Frequency Distribution\n",
        "axes[1].set_title('Frequency Distribution')\n",
        "\n",
        "sns.histplot(rfm_df['Monetary'], ax = axes[2],color='steelblue', kde=True)  # Monetary Distribution\n",
        "axes[2].set_title('Monetary Distribution')\n",
        "\n",
        "plt.show()  # showing graph"
      ],
      "metadata": {
        "id": "FauTCC_r5wYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split into four segments using quantiles\n",
        "quantiles = rfm_df.quantile(q=[0.25,0.5,0.75])\n",
        "quantiles = quantiles.to_dict()\n",
        "quantiles\n",
        ""
      ],
      "metadata": {
        "id": "o1P0pJ6h54ZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Functions to create R, F and M segments according to quantiles for Recency low score is important and for Frequency and Monetory\n",
        "maximum is important. So keeping this in mind we are creating two function to create scores. '''\n",
        "def RScoring(x,p,d):\n",
        "    if x <= d[p][0.25]:\n",
        "        return 1\n",
        "    elif x <= d[p][0.50]:\n",
        "        return 2\n",
        "    elif x <= d[p][0.75]:\n",
        "        return 3\n",
        "    else:\n",
        "        return 4\n",
        "\n",
        "def FnMScoring(x,p,d):\n",
        "    if x <= d[p][0.25]:\n",
        "        return 4\n",
        "    elif x <= d[p][0.50]:\n",
        "        return 3\n",
        "    elif x <= d[p][0.75]:\n",
        "        return 2\n",
        "    else:\n",
        "        return 1\n",
        ""
      ],
      "metadata": {
        "id": "LginDdj558Z-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate Add R, F and M segment value columns in the existing dataset to show R, F and M segment values\n",
        "rfm_df['R'] = rfm_df['Recency'].apply(RScoring, args=('Recency',quantiles))\n",
        "rfm_df['F'] = rfm_df['Frequency'].apply(FnMScoring, args=('Frequency',quantiles))\n",
        "rfm_df['M'] = rfm_df['Monetary'].apply(FnMScoring, args=('Monetary',quantiles))\n",
        "rfm_df.head()"
      ],
      "metadata": {
        "id": "DR-AvIA_6AS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate and Add RFMGroup value column showing combined concatenated score of RFM\n",
        "rfm_df['RFMGroup'] = rfm_df.R.map(str) + rfm_df.F.map(str) + rfm_df.M.map(str)\n",
        "\n",
        "#Calculate and Add RFMScore value column showing total sum of RFMGroup values\n",
        "rfm_df['RFMScore'] = rfm_df[['R', 'F', 'M']].sum(axis = 1)\n",
        "rfm_df.head()"
      ],
      "metadata": {
        "id": "oZmz1rfP6F4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: Customers with an RFM score of 111 are typically our most engaged customers, while those with a score of 444 are at risk of churn."
      ],
      "metadata": {
        "id": "1yt7IzUp6JuJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Handling negative and zero values so as to handle infinite numbers during log transformation\n",
        "def handle_neg_n_zero(num):\n",
        "    if num <= 0:\n",
        "        return 1\n",
        "    else:\n",
        "        return num\n",
        "#Applying handle_neg_n_zero function to Recency and Monetary columns\n",
        "rfm_df['Recency'] = [handle_neg_n_zero(x) for x in rfm_df.Recency]\n",
        "rfm_df['Monetary'] = [handle_neg_n_zero(x) for x in rfm_df.Monetary]\n",
        "\n",
        "#Performing Log transformation to bring data into normal or near normal distribution\n",
        "Log_Tfd_Data = rfm_df[['Recency', 'Frequency', 'Monetary']].apply(np.log, axis = 1).round(3)"
      ],
      "metadata": {
        "id": "KfsynF8d6N34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Distribution after log transformation\n",
        "fig, axes = plt.subplots(1,3,figsize=(20,5))\n",
        "sns.histplot(Log_Tfd_Data['Recency'], ax = axes[0],color='gray', kde=True)  # Recency Distribution\n",
        "axes[0].set_title('Recency Distribution')\n",
        "\n",
        "sns.histplot(Log_Tfd_Data['Frequency'], ax = axes[1],color='brown', kde=True)  # Frequency Distribution\n",
        "axes[1].set_title('Frequency Distribution')\n",
        "\n",
        "sns.histplot(Log_Tfd_Data['Monetary'], ax = axes[2],color='steelblue', kde=True)  # Monetary Distribution\n",
        "axes[2].set_title('Monetary Distribution')\n",
        "\n",
        "plt.show()\n",
        ""
      ],
      "metadata": {
        "id": "r-B2nW7B6N0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Log Transform our Recency, Frequency and Monetary column and store it in new features.\n",
        "rfm_df['Recency_log'] = rfm_df['Recency'].apply(math.log)\n",
        "rfm_df['Frequency_log'] = rfm_df['Frequency'].apply(math.log)\n",
        "rfm_df['Monetary_log'] = rfm_df['Monetary'].apply(math.log)\n",
        ""
      ],
      "metadata": {
        "id": "04Gg7GMF6Up0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2  **K Means Clustering**"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clustering is an unsupervised classification techinque to understand the groups of classes in the data. We use the K-means clustering algorithm to determine the ideal segments of customers.\n",
        "\n",
        "\n",
        "KMeans requires the number of clusters to be specified during the model building process. To know the right number of clusters, methods such as silhouette analysis and elbow method can be used. These methods will help in selection of the optimum number of clusters."
      ],
      "metadata": {
        "id": "E_lPaFU66ncs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Silhouette score method:\n",
        "\n",
        "Silhouette score is used to evaluate the quality of clusters created using clustering algorithms such as K-Means in terms of how well samples are clustered with other samples that are similar to each other. The Silhouette score is calculated for each sample of different clusters."
      ],
      "metadata": {
        "id": "-wPOTF0k6tVf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Applying Silhouette Score Method on Recency and Monetary"
      ],
      "metadata": {
        "id": "r0WJEagT60PI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#silhoutte score\n",
        "features_rec_mon = ['Recency_log','Monetary_log']\n",
        "X_features_rec_mon = rfm_df[features_rec_mon].values\n",
        "\n",
        "scaler_rec_mon = StandardScaler()\n",
        "X_rec_mon = scaler_rec_mon.fit_transform(X_features_rec_mon)   # scaling our features\n",
        "X_rm = X_rec_mon\n",
        "\n",
        "range_n_clusters = [2,3,4,5,6,7,8,9,10,11,12,13,14,15]     # different number of cluster\n",
        "for n_clusters in range_n_clusters:\n",
        "    clusterer = KMeans(n_clusters=n_clusters)       # passing different number of cluster\n",
        "    preds = clusterer.fit_predict(X_rm)\n",
        "    centers = clusterer.cluster_centers_\n",
        "\n",
        "    score = silhouette_score(X_rm, preds)             # calculating silhouette score\n",
        "    print(\"For n_clusters = {}, silhouette score is {}\".format(n_clusters, score))  # printing number of cluster and silhouette score\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Applying Elbow Method on Recency and Monetary:"
      ],
      "metadata": {
        "id": "OMIBUZUS6_Y_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Elbow Method:\n",
        "\n",
        "Elbow is one of the most famous methods by which you can select the right value of k and boost your model performance. We also perform the hyperparameter tuning to chose the best value of k. It is an empirical method to find out the best value of k. it picks up the range of values and takes the best among them. It calculates the sum of the square of the points and calculates the average distance."
      ],
      "metadata": {
        "id": "xBWK56PE7EGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#applying elbow method\n",
        "\n",
        "sum_of_sq_dist = {}\n",
        "for k in range(1,15):\n",
        "    km = KMeans(n_clusters= k, init= 'k-means++', max_iter= 1000)\n",
        "    km = km.fit(X_rm)\n",
        "    sum_of_sq_dist[k] = km.inertia_\n",
        "\n",
        "#Plot the graph for the sum of square distance values and Number of Clusters\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.pointplot(x = list(sum_of_sq_dist.keys()), y = list(sum_of_sq_dist.values()),color='r')\n",
        "plt.xlabel('Number of Clusters(k)',color='blue')\n",
        "plt.ylabel('Sum of Square Distances', color= 'blue')\n",
        "plt.title('Elbow Method For Optimal k', color = 'navy')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ETfESiGx7Gja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Both the silhouette score and the elbow method suggest that a 2-cluster solution may be optimal for this data."
      ],
      "metadata": {
        "id": "6wQzAluU7N4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "kmeans = KMeans(n_clusters=2)\n",
        "kmeans.fit(X_rm)\n",
        "y_kmeans= kmeans.predict(X_rm)\n",
        "# vizualize two cluster\n",
        "plt.figure(figsize=(12,8))  # figure size\n",
        "plt.title('customer segmentation based on Recency and Monetary',color='navy')\n",
        "plt.scatter(X_rm[:, 0], X_rm[:, 1], c=y_kmeans, s=50, cmap='spring_r')\n",
        "\n",
        "centers = kmeans.cluster_centers_\n",
        "plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5)"
      ],
      "metadata": {
        "id": "jA2Kin607Rlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Applying silhouette Score Method on Frquency and Monetary"
      ],
      "metadata": {
        "id": "qp7yt6n-7YT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#silhouetee score\n",
        "features_fre_mon = ['Frequency_log','Monetary_log']\n",
        "X_features_fre_mon = rfm_df[features_fre_mon].values\n",
        "\n",
        "scaler_fre_mon = StandardScaler()\n",
        "X_fre_mon = scaler_fre_mon.fit_transform(X_features_fre_mon)\n",
        "X_fm = X_fre_mon\n",
        "\n",
        "range_n_clusters = [2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
        "for n_clusters in range_n_clusters:\n",
        "    clusterer = KMeans(n_clusters=n_clusters)\n",
        "    preds = clusterer.fit_predict(X_fm)\n",
        "    centers = clusterer.cluster_centers_\n",
        "\n",
        "    score = silhouette_score(X_fm, preds)\n",
        "    print(\"For n_clusters = {}, silhouette score is {}\".format(n_clusters, score))"
      ],
      "metadata": {
        "id": "qowwEg1_7mxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Applying Elbow Method on Frequency and Monetary"
      ],
      "metadata": {
        "id": "ERO1tjnD7vPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#applying elbow method\n",
        "sum_of_sq_dist = {}\n",
        "for k in range(1,15):\n",
        "    km = KMeans(n_clusters= k, init= 'k-means++', max_iter= 1000)\n",
        "    km = km.fit(X_fm)\n",
        "    sum_of_sq_dist[k] = km.inertia_\n",
        "\n",
        "#Plot the graph for the sum of square distance values and Number of Clusters\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.pointplot(x = list(sum_of_sq_dist.keys()), y = list(sum_of_sq_dist.values()),color='r')\n",
        "plt.xlabel('Number of Clusters(k)')\n",
        "plt.ylabel('Sum of Square Distances')\n",
        "plt.title('Elbow Method For Optimal k')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "emyiA4RM7zcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(n_clusters=2)\n",
        "kmeans.fit(X_fm)\n",
        "y_kmeans= kmeans.predict(X_fm)\n",
        "\n",
        "#plotting graph based on frequency and monetary\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.title('customer segmentation based on Frequency and Monetary')\n",
        "plt.scatter(X_fm[:, 0], X_fm[:, 1], c=y_kmeans, s=50, cmap='PRGn')\n",
        "\n",
        "centers = kmeans.cluster_centers_\n",
        "plt.scatter(centers[:, 0], centers[:, 1], c='red', s=200, alpha=0.5)"
      ],
      "metadata": {
        "id": "PKQcl4Pz73yF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Applying Elbow Method on Recency, Frequency and Monetary."
      ],
      "metadata": {
        "id": "4yio7-jR798C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sum_of_sq_dist = {}\n",
        "for k in range(1,15):\n",
        "    km = KMeans(n_clusters= k, init= 'k-means++', max_iter= 1000)\n",
        "    km = km.fit(X)\n",
        "    sum_of_sq_dist[k] = km.inertia_\n",
        "\n",
        "#Plot the graph for the sum of square distance values and Number of Clusters\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.pointplot(x = list(sum_of_sq_dist.keys()), y = list(sum_of_sq_dist.values()),color='r')\n",
        "plt.xlabel('Number of Clusters(k)')\n",
        "plt.ylabel('Sum of Square Distances')\n",
        "plt.title('Elbow Method For Optimal k')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yBn31QBg79I2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unsupervised learning helps us group customers with similar traits for targeted marketing campaigns. To find the best groups, I used silhouette and elbow methods, which are like tools to check how well data points are grouped together. In both cases, the results suggested two groups as the best fit.\n",
        "\n",
        "In unsupervised learning, particularly with K-Means clustering, determining the optimal number of clusters is essential. The elbow and silhouette methods are instrumental in identifying this \"sweet spot\" for the number of clusters."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DBSCAN stands for Density-Based Spatial Clustering of Applications with Noise. DBSCAN is a density-based clustering algorithm that works on the assumption that clusters are dense regions in space separated by regions of lower density.It groups ‘densely grouped’ data points into a single cluster."
      ],
      "metadata": {
        "id": "ATnAtjkSEYHc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Applying DBSCAN on Recency and Monetary"
      ],
      "metadata": {
        "id": "w8sDuBduEb80"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "y_pred = DBSCAN(eps=0.5, min_samples=15).fit_predict(X_rm)\n",
        "plt.figure(figsize=(13,8))\n",
        "plt.scatter(X_rm[:,0], X_rm[:,1], c=y_pred,cmap='spring_r')"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Applying DBSCAN Method on Frquency and Monetary."
      ],
      "metadata": {
        "id": "1Z2PTZ9iEjUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = DBSCAN(eps=0.5, min_samples=15).fit_predict(X_fm)\n",
        "plt.figure(figsize=(13,8))\n",
        "plt.scatter(X_fm[:,0], X_fm[:,1], c=y_pred)"
      ],
      "metadata": {
        "id": "au9kuegjElDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Applying DBSCAN to Recency, Frequency and Monetary."
      ],
      "metadata": {
        "id": "IxzmHpT3EqsG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = DBSCAN(eps=0.5, min_samples=15).fit_predict(X)\n",
        "plt.figure(figsize=(13,8))\n",
        "plt.scatter(X[:,0], X[:,1], c=y_pred)"
      ],
      "metadata": {
        "id": "qzcKbdUpExaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain the model which you have used."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Performing K-Means Clustering with 2 clusters\n",
        "KMean_clust = KMeans(n_clusters= 2, init= 'k-means++', max_iter= 1000)\n",
        "KMean_clust.fit(X)\n",
        "\n",
        "#Find the clusters for the observation given in the dataset\n",
        "rfm_df['Cluster'] = KMean_clust.labels_\n",
        "#First 10 rows of the RFM dataframe\n",
        "rfm_df.head(10)"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#let's check mean values of the cluster for recency, frequnecy and monetary\n",
        "\n",
        "rfm_df.groupby('Cluster').agg({'Recency':'mean',\n",
        "                               'Frequency':'mean',\n",
        "                               'Monetary':'mean'})"
      ],
      "metadata": {
        "id": "mcNbWxzzFarc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "# Specify the Column Names while initializing the Table\n",
        "myTable = PrettyTable(['Sr No.',\"Model_Name\",'Data', \"Optimal_Number_of_cluster\"])\n",
        "\n",
        "# Add rows\n",
        "myTable.add_row(['1',\"K-Means with silhouette_score \", \"RM\", \"2\"])\n",
        "myTable.add_row(['2',\"K-Means with Elbow methos  \", \"RM\", \"2\"])\n",
        "myTable.add_row(['3',\"DBSCAN \", \"RM\", \"2\"])\n",
        "myTable.add_row(['4',\"K-Means with silhouette_score \", \"FM\", \"2\"])\n",
        "myTable.add_row(['5',\"K-Means with Elbow methos  \", \"FM\", \"2\"])\n",
        "myTable.add_row(['6',\"DBSCAN \", \"FM\", \"2\"])\n",
        "myTable.add_row(['7',\"K-Means with silhouette_score \", \"RFM\", \"2\"])\n",
        "myTable.add_row(['8',\"K-Means with Elbow methos  \", \"RFM\", \"2\"])\n",
        "myTable.add_row(['9',\"DBSCAN \", \"RFM\", \"3\"])\n",
        "\n",
        "print(myTable)"
      ],
      "metadata": {
        "id": "0_UuSUj_FhQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "o48OWdLWFk9R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   This project focuses on developing customer segments for a UK-based online store that sells unique, all-occasion gifts.\n",
        "\n",
        "*   Using a recency, frequency, and monetary (RFM) analysis, customers were segmented into various clusters. The analysis resulted in a silhouette score of 0.39 for two clusters.\n",
        "\n",
        "*   By applying different clustering algorithms to the dataset, it was determined that the optimal number of clusters is two.\n",
        "\n",
        "*   The business can now focus on these distinct clusters and tailor its services to each segment accordingly. This targeted approach will benefit both the customers and the business, leading to enhanced customer satisfaction and overall business performance.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IZD2CGh1Fm93"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hurrah! You have successfully completed your Machine Learning Capstone Project !!!**"
      ],
      "metadata": {
        "id": "il1t7VVtGDf4"
      }
    }
  ]
}